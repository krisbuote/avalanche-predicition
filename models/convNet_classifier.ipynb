{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91 images belonging to 5 classes.\n",
      "Found 0 images belonging to 5 classes.\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 21s 4s/step - loss: 3.9904 - acc: 0.3017\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.4370 - acc: 0.4439\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.4133 - acc: 0.3625\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.3734 - acc: 0.4152\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.4284 - acc: 0.3823\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 20s 4s/step - loss: 1.3740 - acc: 0.2750\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.3789 - acc: 0.3381\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.3992 - acc: 0.2670\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 20s 4s/step - loss: 1.3490 - acc: 0.3302\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.3650 - acc: 0.3750\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.3592 - acc: 0.3713\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.3196 - acc: 0.3175\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.3153 - acc: 0.3396\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2586 - acc: 0.4534\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.4363 - acc: 0.4000\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.3749 - acc: 0.3370\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.3400 - acc: 0.3602\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.3386 - acc: 0.3000\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.3223 - acc: 0.3681\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3704 - acc: 0.3934\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 26s 5s/step - loss: 1.3996 - acc: 0.3555\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.2542 - acc: 0.4000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.3079 - acc: 0.4518\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.3526 - acc: 0.3507\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2916 - acc: 0.3444\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.3058 - acc: 0.3570\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.3639 - acc: 0.3096\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3343 - acc: 0.3375\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.3314 - acc: 0.3823\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2820 - acc: 0.4107\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.2939 - acc: 0.3375\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.3589 - acc: 0.3428\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 20s 4s/step - loss: 1.2990 - acc: 0.3659\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3206 - acc: 0.2125\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2920 - acc: 0.3681\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 27s 5s/step - loss: 1.3197 - acc: 0.3634\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.2882 - acc: 0.4281\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.3298 - acc: 0.3125\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1.2260 - acc: 0.4455\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.3100 - acc: 0.4076\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.3163 - acc: 0.3096\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.2259 - acc: 0.4155\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.2228 - acc: 0.4500\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.2512 - acc: 0.4009\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.2237 - acc: 0.4125\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 26s 5s/step - loss: 1.1952 - acc: 0.4487\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1.2605 - acc: 0.3886\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2266 - acc: 0.3981\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.1419 - acc: 0.4234\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2005 - acc: 0.4787\n"
     ]
    }
   ],
   "source": [
    "# Boilerplate code from https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d\n",
    "# Documentation: https://keras.io/preprocessing/image/\n",
    "# Adapted by Kris Buote for Avalanche prediction\n",
    "\n",
    "# The Keras image generator takes existing images and uses the subdirectories as classes. \n",
    "# It creates a larger data set by doing real-time data augmentation.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import os, os.path\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 432, 288\n",
    "\n",
    "train_data_dir = '../data/temp_prec_images/Below Treeline/train/'\n",
    "validation_data_dir = '../data/temp_prec_images/Below Treeline/validation'\n",
    "# nb_train_samples = len([name for name in os.listdir(train_data_dir) if os.path.isfile(name)])\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)]) # count the number of training images\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5)) # 5 neuron outputs danger rating prediction vector. i.e. [0, 0, 1, 0, 0] means rating 3\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False) # consider horizontal_flip = True. I think it would just be \"mirrored in time\"\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
