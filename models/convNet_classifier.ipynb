{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1564 training images. 390 validation images.\n",
      "Found 1564 images belonging to 5 classes.\n",
      "Found 390 images belonging to 5 classes.\n",
      "Epoch 1/50\n",
      "97/97 [==============================] - 509s 5s/step - loss: 1.4679 - acc: 0.3963 - val_loss: 1.2511 - val_acc: 0.4401\n",
      "Epoch 2/50\n",
      "97/97 [==============================] - 554s 6s/step - loss: 1.3565 - acc: 0.4334 - val_loss: 1.2775 - val_acc: 0.4519\n",
      "Epoch 3/50\n",
      "97/97 [==============================] - 623s 6s/step - loss: 1.3281 - acc: 0.4332 - val_loss: 1.2535 - val_acc: 0.4519\n",
      "Epoch 4/50\n",
      "97/97 [==============================] - 655s 7s/step - loss: 1.2877 - acc: 0.4482 - val_loss: 1.2045 - val_acc: 0.4599\n",
      "Epoch 5/50\n",
      "97/97 [==============================] - 586s 6s/step - loss: 1.2663 - acc: 0.4549 - val_loss: 1.1276 - val_acc: 0.4840\n",
      "Epoch 6/50\n",
      "97/97 [==============================] - 551s 6s/step - loss: 1.1842 - acc: 0.4817 - val_loss: 1.0837 - val_acc: 0.4679\n",
      "Epoch 7/50\n",
      "97/97 [==============================] - 556s 6s/step - loss: 1.1545 - acc: 0.4747 - val_loss: 1.0264 - val_acc: 0.5053\n",
      "Epoch 8/50\n",
      "97/97 [==============================] - 560s 6s/step - loss: 1.1265 - acc: 0.4871 - val_loss: 1.0324 - val_acc: 0.4947\n",
      "Epoch 9/50\n",
      "97/97 [==============================] - 550s 6s/step - loss: 1.1188 - acc: 0.4998 - val_loss: 0.9983 - val_acc: 0.5508\n",
      "Epoch 10/50\n",
      "97/97 [==============================] - 549s 6s/step - loss: 1.0862 - acc: 0.5086 - val_loss: 0.9911 - val_acc: 0.5214\n",
      "Epoch 11/50\n",
      "97/97 [==============================] - 550s 6s/step - loss: 1.0851 - acc: 0.5054 - val_loss: 0.9941 - val_acc: 0.5695\n",
      "Epoch 12/50\n",
      "97/97 [==============================] - 540s 6s/step - loss: 1.0667 - acc: 0.5226 - val_loss: 0.9619 - val_acc: 0.5829\n",
      "Epoch 13/50\n",
      "97/97 [==============================] - 540s 6s/step - loss: 1.0477 - acc: 0.5238 - val_loss: 1.0277 - val_acc: 0.5348\n",
      "Epoch 14/50\n",
      "97/97 [==============================] - 542s 6s/step - loss: 1.0335 - acc: 0.5374 - val_loss: 0.9936 - val_acc: 0.5401\n",
      "Epoch 15/50\n",
      "97/97 [==============================] - 543s 6s/step - loss: 1.0399 - acc: 0.5348 - val_loss: 0.9794 - val_acc: 0.5642\n",
      "Epoch 16/50\n",
      "97/97 [==============================] - 533s 5s/step - loss: 1.0245 - acc: 0.5264 - val_loss: 0.9572 - val_acc: 0.5775\n",
      "Epoch 17/50\n",
      "97/97 [==============================] - 530s 5s/step - loss: 1.0195 - acc: 0.5556 - val_loss: 0.9422 - val_acc: 0.5642\n",
      "Epoch 18/50\n",
      "97/97 [==============================] - 531s 5s/step - loss: 0.9898 - acc: 0.5653 - val_loss: 0.9496 - val_acc: 0.5668\n",
      "Epoch 19/50\n",
      "97/97 [==============================] - 529s 5s/step - loss: 1.0045 - acc: 0.5384 - val_loss: 0.9615 - val_acc: 0.5053\n",
      "Epoch 20/50\n",
      "97/97 [==============================] - 532s 5s/step - loss: 0.9738 - acc: 0.5689 - val_loss: 0.9703 - val_acc: 0.5775\n",
      "Epoch 21/50\n",
      "97/97 [==============================] - 531s 5s/step - loss: 0.9925 - acc: 0.5477 - val_loss: 0.9561 - val_acc: 0.5508\n",
      "Epoch 22/50\n",
      "97/97 [==============================] - 531s 5s/step - loss: 0.9711 - acc: 0.5638 - val_loss: 0.9710 - val_acc: 0.5989\n",
      "Epoch 23/50\n",
      "97/97 [==============================] - 534s 6s/step - loss: 0.9864 - acc: 0.5578 - val_loss: 1.0196 - val_acc: 0.5695\n",
      "Epoch 24/50\n",
      "97/97 [==============================] - 541s 6s/step - loss: 0.9516 - acc: 0.5709 - val_loss: 0.9263 - val_acc: 0.5695\n",
      "Epoch 25/50\n",
      "97/97 [==============================] - 530s 5s/step - loss: 0.9376 - acc: 0.5859 - val_loss: 0.9408 - val_acc: 0.5615\n",
      "Epoch 26/50\n",
      "97/97 [==============================] - 532s 5s/step - loss: 0.9614 - acc: 0.5745 - val_loss: 0.9181 - val_acc: 0.5729\n",
      "Epoch 27/50\n",
      "97/97 [==============================] - 536s 6s/step - loss: 0.9089 - acc: 0.6080 - val_loss: 0.9765 - val_acc: 0.5802\n",
      "Epoch 28/50\n",
      "97/97 [==============================] - 529s 5s/step - loss: 0.9589 - acc: 0.6035 - val_loss: 0.9197 - val_acc: 0.6016\n",
      "Epoch 29/50\n",
      "97/97 [==============================] - 531s 5s/step - loss: 0.9006 - acc: 0.6115 - val_loss: 0.9501 - val_acc: 0.5989\n",
      "Epoch 30/50\n",
      "97/97 [==============================] - 532s 5s/step - loss: 0.9195 - acc: 0.5887 - val_loss: 0.8910 - val_acc: 0.6417\n",
      "Epoch 31/50\n",
      "97/97 [==============================] - 540s 6s/step - loss: 0.9413 - acc: 0.5866 - val_loss: 0.8662 - val_acc: 0.6070\n",
      "Epoch 32/50\n",
      "97/97 [==============================] - 538s 6s/step - loss: 0.9249 - acc: 0.6020 - val_loss: 0.8891 - val_acc: 0.6123\n",
      "Epoch 33/50\n",
      "97/97 [==============================] - 537s 6s/step - loss: 0.9031 - acc: 0.6115 - val_loss: 0.9051 - val_acc: 0.6070\n",
      "Epoch 34/50\n",
      "97/97 [==============================] - 532s 5s/step - loss: 0.8932 - acc: 0.6042 - val_loss: 0.8931 - val_acc: 0.6096\n",
      "Epoch 35/50\n",
      "97/97 [==============================] - 531s 5s/step - loss: 0.9021 - acc: 0.5844 - val_loss: 0.9051 - val_acc: 0.5936\n",
      "Epoch 36/50\n",
      "97/97 [==============================] - 530s 5s/step - loss: 0.8840 - acc: 0.6063 - val_loss: 0.8616 - val_acc: 0.6070\n",
      "Epoch 37/50\n",
      "97/97 [==============================] - 528s 5s/step - loss: 0.8644 - acc: 0.6145 - val_loss: 0.9032 - val_acc: 0.5829\n",
      "Epoch 38/50\n",
      "97/97 [==============================] - 527s 5s/step - loss: 0.8730 - acc: 0.6102 - val_loss: 0.8304 - val_acc: 0.6390\n",
      "Epoch 39/50\n",
      "97/97 [==============================] - 529s 5s/step - loss: 0.8715 - acc: 0.6254 - val_loss: 0.9375 - val_acc: 0.5909\n",
      "Epoch 40/50\n",
      "97/97 [==============================] - 529s 5s/step - loss: 0.8792 - acc: 0.6201 - val_loss: 0.8508 - val_acc: 0.6364\n",
      "Epoch 41/50\n",
      "97/97 [==============================] - 532s 5s/step - loss: 0.8306 - acc: 0.6390 - val_loss: 0.9199 - val_acc: 0.5775\n",
      "Epoch 42/50\n",
      "97/97 [==============================] - 531s 5s/step - loss: 0.8235 - acc: 0.6254 - val_loss: 0.8735 - val_acc: 0.6364\n",
      "Epoch 43/50\n",
      "97/97 [==============================] - 530s 5s/step - loss: 0.8487 - acc: 0.6205 - val_loss: 0.8121 - val_acc: 0.6230\n",
      "Epoch 44/50\n",
      "97/97 [==============================] - 531s 5s/step - loss: 0.8518 - acc: 0.6353 - val_loss: 0.9256 - val_acc: 0.5936\n",
      "Epoch 45/50\n",
      "97/97 [==============================] - 530s 5s/step - loss: 0.8068 - acc: 0.6497 - val_loss: 0.7934 - val_acc: 0.6230\n",
      "Epoch 46/50\n",
      "97/97 [==============================] - 540s 6s/step - loss: 0.8180 - acc: 0.6450 - val_loss: 0.9045 - val_acc: 0.6337\n",
      "Epoch 47/50\n",
      "97/97 [==============================] - 533s 5s/step - loss: 0.8265 - acc: 0.6398 - val_loss: 0.8197 - val_acc: 0.6203\n",
      "Epoch 48/50\n",
      "97/97 [==============================] - 533s 5s/step - loss: 0.7946 - acc: 0.6645 - val_loss: 0.8764 - val_acc: 0.6176\n",
      "Epoch 49/50\n",
      "97/97 [==============================] - 529s 5s/step - loss: 0.7884 - acc: 0.6527 - val_loss: 0.7948 - val_acc: 0.6283\n",
      "Epoch 50/50\n",
      "97/97 [==============================] - 529s 5s/step - loss: 0.8541 - acc: 0.6310 - val_loss: 0.8341 - val_acc: 0.6176\n"
     ]
    }
   ],
   "source": [
    "# Boilerplate code from https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d\n",
    "# Documentation: https://keras.io/preprocessing/image/\n",
    "# Adapted by Kris Buote for Avalanche prediction\n",
    "\n",
    "# The Keras image generator takes existing images and uses the subdirectories as classes. \n",
    "# It creates a larger data set by doing real-time data augmentation.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import os, os.path\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 432, 288\n",
    "\n",
    "# area of interest\n",
    "area_path = 'Treeline'\n",
    "\n",
    "train_data_dir = '../data/temp_prec_images/'+ area_path + '/train/'\n",
    "validation_data_dir = '../data/temp_prec_images/' + area_path +'/validation'\n",
    "\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)]) # count the number of training images\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
    "print('{0} training images. {1} validation images.'.format(nb_train_samples, nb_validation_samples))\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5)) # 5 neuron outputs danger rating prediction vector. i.e. [0, 0, 1, 0, 0] means rating 3\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False) # consider horizontal_flip = True. I think it would just be \"mirrored in time\"\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2198 training images. 546 validation images.\n",
      "Found 2198 images belonging to 5 classes.\n",
      "Found 546 images belonging to 5 classes.\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 719s 5s/step - loss: 1.0953 - acc: 0.5397 - val_loss: 0.9730 - val_acc: 0.5588\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 833s 6s/step - loss: 1.0293 - acc: 0.5487 - val_loss: 0.9818 - val_acc: 0.5312\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 749s 5s/step - loss: 0.9844 - acc: 0.5657 - val_loss: 0.9601 - val_acc: 0.5496\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 768s 6s/step - loss: 0.9768 - acc: 0.5707 - val_loss: 0.9414 - val_acc: 0.5699\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 685s 5s/step - loss: 0.9723 - acc: 0.5733 - val_loss: 0.9434 - val_acc: 0.5754\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 757s 6s/step - loss: 0.9449 - acc: 0.5657 - val_loss: 0.9251 - val_acc: 0.6029\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 846s 6s/step - loss: 0.9584 - acc: 0.5874 - val_loss: 0.9288 - val_acc: 0.5901\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 777s 6s/step - loss: 0.9384 - acc: 0.5915 - val_loss: 0.9186 - val_acc: 0.6121\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 710s 5s/step - loss: 0.9147 - acc: 0.6110 - val_loss: 0.9245 - val_acc: 0.6066\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 716s 5s/step - loss: 0.9074 - acc: 0.6077 - val_loss: 0.9321 - val_acc: 0.5938\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 706s 5s/step - loss: 0.8843 - acc: 0.6172 - val_loss: 0.9383 - val_acc: 0.5772\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 717s 5s/step - loss: 0.8980 - acc: 0.6133 - val_loss: 0.9295 - val_acc: 0.5938\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 715s 5s/step - loss: 0.8900 - acc: 0.6230 - val_loss: 0.9509 - val_acc: 0.5717\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 718s 5s/step - loss: 0.8801 - acc: 0.6133 - val_loss: 0.9266 - val_acc: 0.6121\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 698s 5s/step - loss: 0.8594 - acc: 0.6356 - val_loss: 0.9105 - val_acc: 0.6176\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 711s 5s/step - loss: 0.8739 - acc: 0.6239 - val_loss: 0.9287 - val_acc: 0.5993\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 730s 5s/step - loss: 0.8408 - acc: 0.6355 - val_loss: 0.8796 - val_acc: 0.6342\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 727s 5s/step - loss: 0.8346 - acc: 0.6338 - val_loss: 0.9164 - val_acc: 0.6029\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 703s 5s/step - loss: 0.8417 - acc: 0.6414 - val_loss: 0.8807 - val_acc: 0.6397\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 702s 5s/step - loss: 0.8328 - acc: 0.6446 - val_loss: 0.9106 - val_acc: 0.6397\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 703s 5s/step - loss: 0.7988 - acc: 0.6723 - val_loss: 0.8989 - val_acc: 0.6268\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 711s 5s/step - loss: 0.7889 - acc: 0.6630 - val_loss: 0.8930 - val_acc: 0.6489\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 703s 5s/step - loss: 0.8059 - acc: 0.6612 - val_loss: 0.8578 - val_acc: 0.6360\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 685s 5s/step - loss: 0.7857 - acc: 0.6655 - val_loss: 0.8662 - val_acc: 0.6342\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 706s 5s/step - loss: 0.7888 - acc: 0.6621 - val_loss: 0.8685 - val_acc: 0.6379\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 682s 5s/step - loss: 0.7553 - acc: 0.6688 - val_loss: 0.8986 - val_acc: 0.6305\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 703s 5s/step - loss: 0.7749 - acc: 0.6598 - val_loss: 0.8438 - val_acc: 0.6434\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 680s 5s/step - loss: 0.7660 - acc: 0.6717 - val_loss: 0.8514 - val_acc: 0.6305\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 699s 5s/step - loss: 0.7654 - acc: 0.6616 - val_loss: 0.8986 - val_acc: 0.6287\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 682s 5s/step - loss: 0.7393 - acc: 0.6867 - val_loss: 0.8739 - val_acc: 0.6287\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 667s 5s/step - loss: 0.7211 - acc: 0.6817 - val_loss: 0.8748 - val_acc: 0.6415\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 688s 5s/step - loss: 0.7341 - acc: 0.6890 - val_loss: 0.8778 - val_acc: 0.6232\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 665s 5s/step - loss: 0.7280 - acc: 0.6861 - val_loss: 0.8770 - val_acc: 0.6397\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 664s 5s/step - loss: 0.7459 - acc: 0.6744 - val_loss: 0.8671 - val_acc: 0.6379\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 661s 5s/step - loss: 0.7237 - acc: 0.6814 - val_loss: 0.8500 - val_acc: 0.6489\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 673s 5s/step - loss: 0.6996 - acc: 0.6849 - val_loss: 0.8472 - val_acc: 0.6397\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 664s 5s/step - loss: 0.6922 - acc: 0.6953 - val_loss: 0.8692 - val_acc: 0.6379\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 664s 5s/step - loss: 0.6991 - acc: 0.6781 - val_loss: 0.9132 - val_acc: 0.6250\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 661s 5s/step - loss: 0.6841 - acc: 0.7009 - val_loss: 0.8500 - val_acc: 0.6544\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 662s 5s/step - loss: 0.7043 - acc: 0.6981 - val_loss: 0.8708 - val_acc: 0.6415\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 661s 5s/step - loss: 0.7025 - acc: 0.7067 - val_loss: 0.8383 - val_acc: 0.6452\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 664s 5s/step - loss: 0.6894 - acc: 0.7135 - val_loss: 0.8621 - val_acc: 0.6471\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 658s 5s/step - loss: 0.6702 - acc: 0.7065 - val_loss: 0.8751 - val_acc: 0.6526\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.6838 - acc: 0.7000 - val_loss: 0.9029 - val_acc: 0.6397\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 646s 5s/step - loss: 0.6507 - acc: 0.7061 - val_loss: 0.8944 - val_acc: 0.6599\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 662s 5s/step - loss: 0.6733 - acc: 0.7102 - val_loss: 0.8858 - val_acc: 0.6471\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 635s 5s/step - loss: 0.6650 - acc: 0.7114 - val_loss: 0.9102 - val_acc: 0.6507\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 650s 5s/step - loss: 0.6441 - acc: 0.7191 - val_loss: 0.9030 - val_acc: 0.6507\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 645s 5s/step - loss: 0.6420 - acc: 0.7264 - val_loss: 0.9563 - val_acc: 0.6544\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.6533 - acc: 0.7092 - val_loss: 0.9044 - val_acc: 0.6489\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 647s 5s/step - loss: 0.6233 - acc: 0.7181 - val_loss: 0.9361 - val_acc: 0.6250\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 644s 5s/step - loss: 0.6512 - acc: 0.7111 - val_loss: 0.8905 - val_acc: 0.6489\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 637s 5s/step - loss: 0.6551 - acc: 0.7152 - val_loss: 0.9342 - val_acc: 0.6507\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 655s 5s/step - loss: 0.6387 - acc: 0.7207 - val_loss: 0.8690 - val_acc: 0.6342\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 649s 5s/step - loss: 0.6324 - acc: 0.7333 - val_loss: 0.8840 - val_acc: 0.6452\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 639s 5s/step - loss: 0.6275 - acc: 0.7266 - val_loss: 0.9106 - val_acc: 0.6581\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 640s 5s/step - loss: 0.6006 - acc: 0.7450 - val_loss: 0.8897 - val_acc: 0.6287\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 640s 5s/step - loss: 0.5983 - acc: 0.7333 - val_loss: 0.9197 - val_acc: 0.6360\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 647s 5s/step - loss: 0.6350 - acc: 0.7266 - val_loss: 1.0060 - val_acc: 0.6250\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 652s 5s/step - loss: 0.6045 - acc: 0.7319 - val_loss: 0.9406 - val_acc: 0.6507\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 650s 5s/step - loss: 0.6080 - acc: 0.7369 - val_loss: 0.9058 - val_acc: 0.6434\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 648s 5s/step - loss: 0.6118 - acc: 0.7324 - val_loss: 0.9279 - val_acc: 0.6268\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.5850 - acc: 0.7470 - val_loss: 1.0047 - val_acc: 0.6434\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.5787 - acc: 0.7543 - val_loss: 0.9171 - val_acc: 0.6434\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 655s 5s/step - loss: 0.5825 - acc: 0.7395 - val_loss: 0.9579 - val_acc: 0.6342\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.6032 - acc: 0.7371 - val_loss: 0.9704 - val_acc: 0.6452\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 649s 5s/step - loss: 0.5991 - acc: 0.7506 - val_loss: 0.9817 - val_acc: 0.6029\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 654s 5s/step - loss: 0.5704 - acc: 0.7459 - val_loss: 0.9486 - val_acc: 0.6710\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 654s 5s/step - loss: 0.5919 - acc: 0.7386 - val_loss: 0.9045 - val_acc: 0.6471\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 656s 5s/step - loss: 0.6060 - acc: 0.7263 - val_loss: 1.0897 - val_acc: 0.6342\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 653s 5s/step - loss: 0.5796 - acc: 0.7579 - val_loss: 0.9512 - val_acc: 0.6562\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 652s 5s/step - loss: 0.5821 - acc: 0.7529 - val_loss: 0.9362 - val_acc: 0.6397\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 649s 5s/step - loss: 0.5678 - acc: 0.7597 - val_loss: 0.9701 - val_acc: 0.6452\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 650s 5s/step - loss: 0.5891 - acc: 0.7436 - val_loss: 0.9679 - val_acc: 0.6379\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 652s 5s/step - loss: 0.5586 - acc: 0.7644 - val_loss: 1.0419 - val_acc: 0.6324\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 650s 5s/step - loss: 0.5559 - acc: 0.7606 - val_loss: 0.9406 - val_acc: 0.6434\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.5723 - acc: 0.7599 - val_loss: 0.9428 - val_acc: 0.6379\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.5493 - acc: 0.7504 - val_loss: 0.9898 - val_acc: 0.6415\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 646s 5s/step - loss: 0.5459 - acc: 0.7594 - val_loss: 0.9918 - val_acc: 0.6415\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 646s 5s/step - loss: 0.5478 - acc: 0.7658 - val_loss: 0.9551 - val_acc: 0.6452\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 646s 5s/step - loss: 0.5409 - acc: 0.7506 - val_loss: 1.0378 - val_acc: 0.6305\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 651s 5s/step - loss: 0.5561 - acc: 0.7632 - val_loss: 0.9715 - val_acc: 0.6489\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 646s 5s/step - loss: 0.5622 - acc: 0.7657 - val_loss: 0.9989 - val_acc: 0.6434\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 647s 5s/step - loss: 0.5714 - acc: 0.7515 - val_loss: 1.0422 - val_acc: 0.6415\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 649s 5s/step - loss: 0.5578 - acc: 0.7590 - val_loss: 1.0085 - val_acc: 0.6471\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.5454 - acc: 0.7552 - val_loss: 1.0151 - val_acc: 0.6434\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 650s 5s/step - loss: 0.5215 - acc: 0.7670 - val_loss: 1.0125 - val_acc: 0.6599\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 649s 5s/step - loss: 0.5530 - acc: 0.7686 - val_loss: 0.9844 - val_acc: 0.6342\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 649s 5s/step - loss: 0.5552 - acc: 0.7518 - val_loss: 0.9992 - val_acc: 0.6452\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 648s 5s/step - loss: 0.5467 - acc: 0.7514 - val_loss: 1.0378 - val_acc: 0.6287\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 655s 5s/step - loss: 0.5413 - acc: 0.7652 - val_loss: 0.9707 - val_acc: 0.6526\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 657s 5s/step - loss: 0.5266 - acc: 0.7555 - val_loss: 1.0525 - val_acc: 0.6507\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 649s 5s/step - loss: 0.5433 - acc: 0.7646 - val_loss: 0.9687 - val_acc: 0.6379\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 651s 5s/step - loss: 0.5315 - acc: 0.7806 - val_loss: 1.0164 - val_acc: 0.6397\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 1820s 13s/step - loss: 0.5398 - acc: 0.7664 - val_loss: 1.0072 - val_acc: 0.6176\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 1075s 8s/step - loss: 0.5227 - acc: 0.7684 - val_loss: 1.0205 - val_acc: 0.6452\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 690s 5s/step - loss: 0.5252 - acc: 0.7660 - val_loss: 0.9940 - val_acc: 0.6544\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 659s 5s/step - loss: 0.5430 - acc: 0.7711 - val_loss: 1.0121 - val_acc: 0.6618\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 1409s 10s/step - loss: 0.5478 - acc: 0.7670 - val_loss: 0.9209 - val_acc: 0.6544\n",
      "Epoch 1/1\n",
      "137/137 [==============================] - 1046s 8s/step - loss: 0.5212 - acc: 0.7740 - val_loss: 0.9928 - val_acc: 0.6397\n"
     ]
    }
   ],
   "source": [
    "# Continue training model from saved weights\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import os, os.path\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 432, 288\n",
    "\n",
    "# area of interest\n",
    "area_path = 'Treeline'\n",
    "\n",
    "train_data_dir = '../data/temp_prec_images/'+ area_path + '/train/'\n",
    "validation_data_dir = '../data/temp_prec_images/' + area_path +'/validation'\n",
    "\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)]) # count the number of training images\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
    "print('{0} training images. {1} validation images.'.format(nb_train_samples, nb_validation_samples))\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5)) # 5 neuron outputs danger rating prediction vector. i.e. [0, 0, 1, 0, 0] means rating 3\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.load_weights('./first_try.h5')\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False) # consider horizontal_flip = True. I think it would just be \"mirrored in time\"\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "    if epoch%5 == 0: # Every 5 epochs, save weights\n",
    "        model.save_weights('second_try_epoch'+ str(epoch) +'.h5')\n",
    "\n",
    "model.save_weights('second_try_epoch'+ str(epochs) +'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
