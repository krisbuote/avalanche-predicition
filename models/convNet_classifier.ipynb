{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 285 images belonging to 5 classes.\n",
      "Found 62 images belonging to 5 classes.\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 78s 5s/step - loss: 2.3265 - acc: 0.3897 - val_loss: 1.2883 - val_acc: 0.3125\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 75s 4s/step - loss: 1.2438 - acc: 0.3748 - val_loss: 1.0313 - val_acc: 0.5217\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 88s 5s/step - loss: 1.2310 - acc: 0.4471 - val_loss: 1.1498 - val_acc: 0.2609\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 100s 6s/step - loss: 1.2619 - acc: 0.4115 - val_loss: 1.0473 - val_acc: 0.5217\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 104s 6s/step - loss: 1.2331 - acc: 0.3740 - val_loss: 1.1499 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 113s 7s/step - loss: 1.2047 - acc: 0.3858 - val_loss: 1.0505 - val_acc: 0.5217\n",
      "Epoch 7/50\n",
      "15/17 [=========================>....] - ETA: 9s - loss: 1.2127 - acc: 0.4333 "
     ]
    }
   ],
   "source": [
    "# Boilerplate code from https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d\n",
    "# Documentation: https://keras.io/preprocessing/image/\n",
    "# Adapted by Kris Buote for Avalanche prediction\n",
    "\n",
    "# The Keras image generator takes existing images and uses the subdirectories as classes. \n",
    "# It creates a larger data set by doing real-time data augmentation.\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import os, os.path\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 432, 288\n",
    "\n",
    "train_data_dir = '../data/temp_prec_images/Below Treeline/train/'\n",
    "validation_data_dir = '../data/temp_prec_images/Below Treeline/validation'\n",
    "\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)]) # count the number of training images\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5)) # 5 neuron outputs danger rating prediction vector. i.e. [0, 0, 1, 0, 0] means rating 3\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False) # consider horizontal_flip = True. I think it would just be \"mirrored in time\"\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
